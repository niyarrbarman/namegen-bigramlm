{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Reading Data"
      ],
      "metadata": {
        "id": "QmpYr-aWH8Kb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('names.txt', 'r') as f:\n",
        "    text = f.read()"
      ],
      "metadata": {
        "id": "bDHQc756qoAT"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9vQAb9bquX0",
        "outputId": "e0df2301-4953-4715-a1e9-5d447228a76a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "228145"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## First 100 chars"
      ],
      "metadata": {
        "id": "P0YQqmlNIAVR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(text[:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FxuTrx-FsZ4P",
        "outputId": "a2823f63-29f6-4ab9-9287-49ee0693f5ba"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "emma\n",
            "olivia\n",
            "ava\n",
            "isabella\n",
            "sophia\n",
            "charlotte\n",
            "mia\n",
            "amelia\n",
            "harper\n",
            "evelyn\n",
            "abigail\n",
            "emily\n",
            "elizabeth\n",
            "mila\n",
            "ella\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vocabulary and vocab size"
      ],
      "metadata": {
        "id": "QQTu59kvIDx5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "print(\"\".join(chars))\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nk4Ay4apseJL",
        "outputId": "ef4d7dfa-183b-445e-e711-e72d7b0e0f08"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "abcdefghijklmnopqrstuvwxyz\n",
            "27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoder and decoder"
      ],
      "metadata": {
        "id": "M_xOeKJIIHkM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stoi = { ch : i for i, ch in enumerate(chars)}\n",
        "itos = { i : ch for i, ch in enumerate(chars)}\n",
        "\n",
        "encode = lambda s: [stoi[c] for c in s]\n",
        "decode = lambda l: \"\".join([itos[i] for i in l])"
      ],
      "metadata": {
        "id": "nQBQIRxfsq6y"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encode(\"hello\\nworld\"), decode(encode(\"hello\\nworld\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxLgH1CwuQ_k",
        "outputId": "9e086035-d4e4-4762-e3d7-bfd690387ce2"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([8, 5, 12, 12, 15, 0, 23, 15, 18, 12, 4], 'hello\\nworld')"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataloader"
      ],
      "metadata": {
        "id": "nlELCKXqINh9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "print(data.shape, data.dtype)\n",
        "print(text[:100], data[:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dANm6iWyuuhF",
        "outputId": "5ffd906a-b250-437e-d198-7768b7cd8b4f"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([228145]) torch.int64\n",
            "emma\n",
            "olivia\n",
            "ava\n",
            "isabella\n",
            "sophia\n",
            "charlotte\n",
            "mia\n",
            "amelia\n",
            "harper\n",
            "evelyn\n",
            "abigail\n",
            "emily\n",
            "elizabeth\n",
            "mila\n",
            "ella tensor([ 5, 13, 13,  1,  0, 15, 12,  9, 22,  9,  1,  0,  1, 22,  1,  0,  9, 19,\n",
            "         1,  2,  5, 12, 12,  1,  0, 19, 15, 16,  8,  9,  1,  0,  3,  8,  1, 18,\n",
            "        12, 15, 20, 20,  5,  0, 13,  9,  1,  0,  1, 13,  5, 12,  9,  1,  0,  8,\n",
            "         1, 18, 16,  5, 18,  0,  5, 22,  5, 12, 25, 14,  0,  1,  2,  9,  7,  1,\n",
            "         9, 12,  0,  5, 13,  9, 12, 25,  0,  5, 12,  9, 26,  1,  2,  5, 20,  8,\n",
            "         0, 13,  9, 12,  1,  0,  5, 12, 12,  1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = int(0.9*len(data))\n",
        "train_data = data[:n]\n",
        "valid_data = data[n:]"
      ],
      "metadata": {
        "id": "e4vqKrVdvHIP"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "block_size=8\n",
        "train_data[:block_size + 1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtJgrlcQvkcg",
        "outputId": "9e21d502-5159-477e-cbec-4a40a5e2742f"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 5, 13, 13,  1,  0, 15, 12,  9, 22])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = train_data[:block_size]\n",
        "y = train_data[1:block_size+1]\n",
        "for t in range(block_size):\n",
        "    context = x[:t+1]\n",
        "    target = y[t]\n",
        "    print(f\"when input is {context}, output is {target}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6OrBiT-Nv5sU",
        "outputId": "43ad2492-ad84-46e0-e9a9-aec9078b2891"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "when input is tensor([5]), output is 13\n",
            "when input is tensor([ 5, 13]), output is 13\n",
            "when input is tensor([ 5, 13, 13]), output is 1\n",
            "when input is tensor([ 5, 13, 13,  1]), output is 0\n",
            "when input is tensor([ 5, 13, 13,  1,  0]), output is 15\n",
            "when input is tensor([ 5, 13, 13,  1,  0, 15]), output is 12\n",
            "when input is tensor([ 5, 13, 13,  1,  0, 15, 12]), output is 9\n",
            "when input is tensor([ 5, 13, 13,  1,  0, 15, 12,  9]), output is 22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1337)\n",
        "batch_size = 4\n",
        "block_size = 8\n",
        "\n",
        "def get_batch(split):\n",
        "    data = train_data if split == 'train' else valid_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([data[i: i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1: i+block_size+1] for i in ix])\n",
        "    return x, y\n",
        "\n",
        "xb, yb = get_batch('train')\n",
        "print('input')\n",
        "print(xb.shape)\n",
        "print(xb)\n",
        "print('target:')\n",
        "print(xb.shape)\n",
        "print(xb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2gpNMwTwXzt",
        "outputId": "a0aa57c5-20aa-4f91-c6f8-475f2d18014e"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input\n",
            "torch.Size([4, 8])\n",
            "tensor([[12,  9, 25,  1,  8,  0,  5, 13],\n",
            "        [ 0, 13,  1,  5, 12,  9, 14,  0],\n",
            "        [12, 15, 18, 25, 14, 14,  0, 12],\n",
            "        [ 5, 15, 12, 21, 23,  1,  0, 15]])\n",
            "target:\n",
            "torch.Size([4, 8])\n",
            "tensor([[12,  9, 25,  1,  8,  0,  5, 13],\n",
            "        [ 0, 13,  1,  5, 12,  9, 14,  0],\n",
            "        [12, 15, 18, 25, 14, 14,  0, 12],\n",
            "        [ 5, 15, 12, 21, 23,  1,  0, 15]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "S54maLI6IQep"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "torch.manual_seed(1337)\n",
        "\n",
        "class BigramLM(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super().__init__()\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        logits = self.token_embedding_table(idx) #B,T,C\n",
        "\n",
        "        if targets is None:\n",
        "            loss=None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        for _ in range(max_new_tokens):\n",
        "            logits, loss = self(idx)\n",
        "            logits = logits[:, -1, :]\n",
        "            output = F.softmax(logits, dim=1)\n",
        "            idx_next = torch.multinomial(output, num_samples=1)\n",
        "            idx = torch.cat((idx, idx_next), dim=1)\n",
        "\n",
        "        return idx"
      ],
      "metadata": {
        "id": "s9rjdK-K2mgK"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BigramLM(vocab_size)\n",
        "logits, loss = model(xb, yb)\n",
        "print(logits.shape, loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHJiwcCD8-O_",
        "outputId": "5a54e418-fb0a-4c4d-955f-6df2a5e50fb5"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 27]) tensor(3.7703, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model output without training"
      ],
      "metadata": {
        "id": "1uYmCMHKISXe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "idx=torch.tensor([[1]], dtype=torch.long)\n",
        "print(decode((model.generate(idx, max_new_tokens=100)[0]).tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDEBLQi-9I1H",
        "outputId": "e29824f2-4ebc-4585-f67a-404394092c29"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aqvwhxqtxuopubgachrnladkcrvg\n",
            "oswhxcztawewh\n",
            "ilxjpeptgclcqebrnwzzlophxjceittkrqymcrgedcljsscdyaadeczthm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4)"
      ],
      "metadata": {
        "id": "VdPNTb08_F5V"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "for steps in range(100000):\n",
        "    xb, yb = get_batch('train')\n",
        "    logits, loss = model(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6hjPFtuBltP",
        "outputId": "330e8fb4-df7d-48fc-f472-db24ed206fbf"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.387847900390625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sample output after training"
      ],
      "metadata": {
        "id": "mG4vJ3JnIXdu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "idx=torch.randint(0,27,(1,1), dtype=torch.long)\n",
        "print(\"Input char is : \", decode(idx[0].tolist()))\n",
        "print(f\"Outputs:\\n{decode((model.generate(idx, max_new_tokens=5)[0]).tolist())}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ws-mspzOCEnR",
        "outputId": "73f72327-2f59-4f22-b955-6c8c69c10b8d"
      },
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input char is :  z\n",
            "Outputs:\n",
            "zaviah\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C4DmTSZ4CcB6"
      },
      "execution_count": 181,
      "outputs": []
    }
  ]
}